#!/usr/bin/env python
#
# filterator -- filter and format the output of comparator
#
import os, sys, re, getopt

# Tokens to be removed when checking whether a shred is significant
junk = {
    "C": map(re.compile, (
        # Idioms that don't convey any meaning in isolation
        r"return *\(?[a-z]+\)? *;", r"return *\(?-?[01]+\)? *;",
        r"goto +[a-z]+;", r"exit *\([01]\);",
        # Pragmas
        r'/\* *ARGSUSED *\*/', r'/\* *NOTREACHED *\*/', 
        # Bare C keywords
        r'\bbreak\b',  r'\bcase\b',r'\bcontinue\b', r'\bdefault\b',
        r'\bdo\b', r'\belse\b', r'\benum\b', r'\bif\b', r'\bgoto\b',
        r'\breturn\b', r'\bswitch\b', r'\bwhile\b',
        r'enum', r'\bint\b', r'\blong\b', r'\bshort\b', r'\bstatic\b',
        r'\bstruct\b', r'typedef', r'\bunion\b', r'\bvoid\b',
        r'# *define',r'# *endif',r'# *else',r'# *if\b',
        r'# *ifdef\b',r'# *ifndef\b',
        # Comment delimiters with no content
        r'/\*+', r'\*+/', r'\*+', r'^ *\\s*\n',
        # Common preprocessor macros, not significant by themselves.
        r'\bASSERT\b', r'\bFALSE\b', r'\bNULL\b', r'\bSTATIC\b', r'\bTRUE\b',
        # Macro include lines are noise, too.
        r'\s*#include.*',r'#\s*line.*',
        # Common error macros.
        r'\bEFAULT\b', r'\bEINVAL\b', r'\bENOSYS\b',
        # Punctuation and whitespace
        r'\{', r'\}', r'\(', r'\)', r'\<', r'\>', r'\[', r'\]',
        r'\^', '&', r'\|', r'\*', r'\?', r'\.', r'\+', 
        '\\\n', ';', ':', '%', ',', '-', '/', '=', '!', '\n','\t', '\v'
        )),
    "shell": map(re.compile, (
        # Idioms that don't convey any meaning in isolation
        r"exit *[01];?",
        # Bare shell keywords
        r"\bbreak\b", r"\bcase\b", r"\bdone\b", r"\bdo\b", r"\belse\b",
        r"\besac\b", r"\bfi\b", r"\bif\b", r"\breturn\b", r"\bshift\b",
        r"\btrue\b", r"\bwhile\b", 
        # Blank comment
        "^#\n",
        # Punctuation and whitespace
        ':', ';', '\n','\t', '\v'
        )),
    }

def nontrivial(filetype, text):
    "Identify a shred as trivial or nontrivial."
    if filetype:
        if debug:
            print "New shred, type %s:" % `filetype`
            sys.stdout.write(text)
        # Basic theory of this function is that if we throw out all C
        # syntax and and common constants, and there is still an
        # identifier, we're looking at something that might be
        # interesting.
        text = ' ' + text
        while 1:
            savecopy = text
            for regexp in junk[filetype]:
                text = regexp.sub(' ', text)
            if savecopy == text:
                break
            else:
                if debug:
                    print "Reduced:", `text`
                continue
    return text.strip()

class CommonReport:
    "Capture the state of common-segnent report."
    # Template for parsing the output from comparator.
    shredline = re.compile("(.*):([0-9]+):([0-9]+):([0-9]+)")

    def __init__(self, fp):
        # Read the SCF header
        self.hash_method = "RXOR"
        self.merge_program = None
        id = fp.readline()
        if not id.startswith("#SCF-B "):
            sys.stderr.write("filterator: input is not a SCF-B file.\n")
            sys.exit(1)
        # Read metadata
        while 1:
            line = fp.readline()
            if not line or line == '%%\n':
                break
            (tag, value) = line.split(":")
            value = value.strip()
            if tag == "Normalization":
                self.normalization = value
            elif tag == "Shred-Size":
                self.shredsize = int(value)
            elif tag == "Merge-Program":
                self.merge_program = value
            elif tag == "Hash-Method":
                self.hash_method = value
        # Read file statistics
        self.trees = {}
        while 1:
            line = fp.readline()
            if not line or line == '%%\n':
                break
            (tag, value) = line.split(":")
            self.trees[tag] = int(value.strip())
        # Now read the common-segment stuff
        self.cliques = []
        self.files = {}
        locations = []
        while 1:
            line = fp.readline()
            if not line:
                break
            m = CommonReport.shredline.search(line)
            if m:
                (file, start, end, length) = \
                       (m.group(1), int(m.group(2)),
                        int(m.group(3)), int(m.group(4)))
                locations.append((file, start, end))
                self.files[file] = length
            if line == '%%\n':
                self.cliques.append(locations)
                locations = []

    def segment_count(self):
        "Number of common chunks in the report."
        return len(self.cliques)

    def line_count(self, tree):
        "Number of common lines from a specified tree."
        lines = 0
        for clique in self.cliques:
            for (file, start, end) in clique:
                # We find only the first match in the clique that
                # is part of the specified tree.  There could be others,
                # and if whitespace removal is in effect they could
                # have different names.
                if file.startswith(tree):
                    lines += end - start + 1
                    break
        return lines

    def extract_text(self, clique):
        "Return text corresponding to the given clique."
        for (file, start, end) in clique:
            try:
                # Try to deduce the text_type
                text_type = None
                if file.endswith(".c") or file.endswith(".h"):
                    text_type = "C"
                # Skip to the relevant chunk
                rfp = open(file)
                for i in range(start-1):
                    line = rfp.readline()
                    if not text_type and i == 0:
                        if "sh" in line:
                            text_type = "shell"
                text = ""
                for i in range(start, end+1):
                    nextline = rfp.readline()
                    if not text_type and i == 0 and start == 1:
                        if "sh" in line:
                            text_type = "shell"
                    if nextline[0] == '%':
                        nextline = '%' + nextline
                    text += nextline
                rfp.close()
                break
            except IOError:
                sys.stderr.write("filterator: can't open %s\n" % file)
                sys.exit(0)
        return (text_type, text)

    def filter_by_size(self, minsize):
        "Throw out all common segments below a specified size."
        filtered = []
        for clique in self.cliques:
            for (file, start, end) in clique:
                if end - start + 1 >= minsize:
                    filtered.append(clique)
                    break
        self.cliques = filtered

    def filter_by_significance(self):
        "Throw out all cliques that aren't significant."
        self.cliques = filter(
            		lambda x: apply(nontrivial,self.extract_text(x)),
                        self.cliques)

def report_common(state):
    "Generate a report on common code."
    print "Filter-Program: filterator 1.0"
    print "Filtering:", ("none", "language")[dofilter]
    print "Hash-Method: MD5"
    if state.merge_program:
        print "Merge-Program:", state.merge_program
    print "Normalization:", state.normalization
    print "Shred-Size: %d" % state.shredsize
    if minsize:
        print "Minimum-Size: %d" % minsize
    if stats:
        print 75 * '-'
        print "# %d overlaps." % state.segment_count()
        for (tree, totallines) in state.trees.items():
            lines = state.line_count(tree)
            print "# %f%% of %s" % ((lines*100.0)/totallines, tree)
    print 75 * '-'
    for clique in state.cliques:
        for (file, start, end) in clique:
            if start == 1 and end == state.files[file]:
                print "%% %s:%d-%d: entire (%d matches)" % (file, start, end, len(clique))
                continue
        (text_type, text) = state.extract_text(clique)
        print "%% %s:%d-%d: (%d matches)" % (file, start, end, len(clique))
        sys.stdout.write(state.extract_text(clique)[1])

if __name__ == '__main__':
    try:
        (optlist, args) = getopt.getopt(sys.argv[1:], 'd:ns:Sx')
    except getopt.GetoptError:
        sys.stderr.write("usage: filterator [-d dir] [-m size] [-n] [-x]\n")
        sys.exit(2)
    stats = debug = 0
    dofilter = 1
    minsize = 5
    linecounts = {}
    for (opt, val) in optlist:
        if opt == '-d':
            os.chdir(val)
        elif opt == '-m':
            minsize = int(val)
        elif opt == '-n':
            dofilter = 0
        elif opt == '-S':
            stats = 1
        elif opt == '-x':
            debug = 1

    state = CommonReport(sys.stdin)
    if minsize:
        state.filter_by_size(minsize)
    if dofilter:
        state.filter_by_significance()

    if stats:
        print "%d overlaps" % state.segment_count()
        for (tree, totallines) in state.trees.items():
            lines = state.line_count(tree)
            print "%s:%d:%d" % (tree, lines, state.trees[tree])
    else:
        report_common(state)
